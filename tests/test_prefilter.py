import os
import sys
import pandas as pd
import psycopg2
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv

# Add the project root to sys.path to ensure imports work correctly
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Import the database connection function from the project
from SRAgent.db.connect import db_connect

def get_db_connection():
    """Get database connection using the project's db_connect function."""
    try:
        # Use the same connection method as the rest of the project
        conn = db_connect()
        return conn
    except Exception as e:
        print(f"âŒ Database connection failed: {e}")
        return None

# For testing purposes, we need to redefine some core classes here (in actual use, these would be imported from the prefilter module)
from dataclasses import dataclass
import pandas as pd

@dataclass
class FilterResult:
    """
    Filter result data class.
    """
    data: pd.DataFrame
    count: int
    filter_name: str
    description: str
    reduction_count: int = 0
    reduction_pct: float = 0.0
    
    def __post_init__(self):
        if self.data is not None:
            self.count = len(self.data)
    
    def log_result(self, previous_count: int = None):
        if previous_count is not None:
            self.reduction_count = previous_count - self.count
            self.reduction_pct = (self.reduction_count / previous_count * 100) if previous_count > 0 else 0
            
        print(f"ğŸ“Š {self.filter_name}: {self.count:,} records "
              f"(â†“{self.reduction_count:,}, -{self.reduction_pct:.1f}%)")
        if self.description:
            print(f"   {self.description}")

def execute_query_with_cursor(conn, query, params):
    """
    Execute query and return DataFrame.
    """
    try:
        cursor = conn.cursor()
        cursor.execute(query, params)
        
        if cursor.description is None:
            cursor.close()
            return pd.DataFrame()
        
        colnames = [desc[0] for desc in cursor.description]
        results = cursor.fetchall()
        cursor.close()
        
        return pd.DataFrame(results, columns=colnames)
        
    except Exception as e:
        print(f"Database query error: {e}")
        try:
            cursor.close()
        except:
            pass
        return pd.DataFrame()

# Simplified filter classes for testing
class TestInitialDatasetFilter:
    def __init__(self, conn, table_name="merged.sra_geo_ft"):
        self.conn = conn
        self.table_name = table_name
    
    def apply(self, input_result=None):
        query = f"""
            SELECT "sra_ID", study_title, summary, overall_design, scientific_name, 
                   library_strategy, technology, characteristics_ch1, gse_title, gsm_title,
                   organism_ch1, source_name_ch1, common_name, gsm_submission_date, sc_conf_score
            FROM {self.table_name}
            LIMIT 1000  -- Limit number of records for faster testing
        """
        
        df = execute_query_with_cursor(self.conn, query, ())
        result = FilterResult(
            data=df,
            count=len(df),
            filter_name="Initial Dataset",
            description="Sample records from database"
        )
        result.log_result()
        return result

class TestBasicAvailabilityFilter:
    def __init__(self, conn):
        self.conn = conn
    
    def apply(self, input_result):
        if input_result.data.empty:
            return FilterResult(pd.DataFrame(), 0, "Basic Availability", "No input data")
        
        # Check data availability for debugging
        total_records = len(input_result.data)
        sra_id_available = input_result.data['sra_ID'].notna().sum() if 'sra_ID' in input_result.data.columns else 0
        non_empty_sra_id = (input_result.data['sra_ID'].notna() & (input_result.data['sra_ID'] != '')).sum() if 'sra_ID' in input_result.data.columns else 0
        gse_title_available = input_result.data['gse_title'].notna().sum() if 'gse_title' in input_result.data.columns else 0
        
        print(f"   Debug - Total: {total_records}, SRA ID available: {sra_id_available}, "
              f"Non-empty SRA ID: {non_empty_sra_id}, GSE title available: {gse_title_available}")
        
        # Use a more relaxed filter condition for testing
        sra_mask = pd.Series([False] * len(input_result.data), index=input_result.data.index)
        gse_mask = pd.Series([False] * len(input_result.data), index=input_result.data.index)
        
        if 'sra_ID' in input_result.data.columns:
            sra_mask = input_result.data['sra_ID'].notna() & (input_result.data['sra_ID'] != '')
        
        if 'gse_title' in input_result.data.columns:
            gse_mask = input_result.data['gse_title'].notna()
        
        # Allow records with either SRA ID or GSE title (more permissive)
        filtered_df = input_result.data[sra_mask | gse_mask].copy()
        
        result = FilterResult(
            data=filtered_df,
            count=len(filtered_df),
            filter_name="Basic Availability",
            description="Has SRA_ID or GSE title"
        )
        result.log_result(input_result.count)
        return result

class TestOrganismFilter:
    # Common false positive keywords that should be excluded even if they match human
    EXCLUDE_PATTERNS = [
        r'\bmouse\b', r'\bmurine\b', r'\bmus musculus\b',  # Mouse-related terms
        r'\brat\b', r'\brattus\b', r'\brattus norvegicus\b',  # Rat-related terms
        r'\bfruit fly\b', r'\bdrosophila\b', r'\bdrosophila melanogaster\b',  # Fruit fly
        r'\bzebrafish\b', r'\bdanio rerio\b',  # Zebrafish
        r'\bmonkey\b', r'\bmacaque\b', r'\brhesus\b',  # Non-human primates
        r'\bmodel organism\b',  # Generic model organism mentions
        r'\bcell line\b',  # Cell lines that might be human but are not primary tissue
        r'\bhepg2\b', r'\bhek293\b', r'\bhela\b',  # Common human cell lines
        r'\bxenograft\b',  # Xenograft models (human cells in other organisms)
        r'\bhumanized\b',  # Humanized models (modified organisms)
        r'\bsars-cov\b', r'\bsars cov\b', r'\bcovid\b', r'\bsars-2\b', r'\bnovel coronavirus\b',  # Viruses often associated with humans
        r'\bh1n1\b', r'\bh3n2\b', r'\binfluenza\b',  # Influenza viruses
        r'\bhiv\b', r'\bhepatitis\b', r'\bebv\b', r'\bepstein-barr\b',  # Other human-associated viruses
        r'\bvirus\b.*\bhomo sapiens\b', r'\bhomo sapiens\b.*\bvirus\b'  # Virus and human co-occurrence patterns
    ]
    
    def __init__(self, conn, organisms):
        self.conn = conn
        self.organisms = organisms
    
    def apply(self, input_result):
        if input_result.data.empty or "human" not in [org.lower() for org in self.organisms]:
            return input_result
        
        # Filter records with specified organisms in memory
        human_mask = (
            input_result.data['organism_ch1'].str.contains('homo sapiens', case=False, na=False) |
            input_result.data['scientific_name'].str.contains('homo sapiens', case=False, na=False) |
            input_result.data['source_name_ch1'].str.contains('human', case=False, na=False) |
            input_result.data['common_name'].str.contains('human', case=False, na=False)
        )
        
        # Create exclusion mask for false positive keywords (only in the same 5 columns used for human matching)
        exclude_mask = pd.Series([False] * len(input_result.data), index=input_result.data.index)
        human_matching_columns = ['organism_ch1', 'scientific_name', 'organism', 'source_name_ch1', 'common_name']
        
        for pattern in self.EXCLUDE_PATTERNS:
            for col in human_matching_columns:
                if col in input_result.data.columns:
                    exclude_mask |= input_result.data[col].str.contains(pattern, case=False, na=False, regex=True)
        
        # Apply both inclusion and exclusion filters
        final_mask = human_mask & ~exclude_mask
        filtered_df = input_result.data[final_mask].copy()
        
        result = FilterResult(
            data=filtered_df,
            count=len(filtered_df),
            filter_name="Organism Filter",
            description="Human samples only (excluded common false positives including viruses)"
        )
        result.log_result(input_result.count)
        return result

class TestSingleCellFilter:
    def __init__(self, conn, min_confidence=2):
        self.conn = conn
        self.min_confidence = min_confidence
    
    def apply(self, input_result):
        if input_result.data.empty or 'sc_conf_score' not in input_result.data.columns:
            return input_result
        
        sc_mask = (
            input_result.data['sc_conf_score'].notna() & 
            (input_result.data['sc_conf_score'] >= self.min_confidence)
        )
        
        filtered_df = input_result.data[sc_mask].copy()
        result = FilterResult(
            data=filtered_df,
            count=len(filtered_df),
            filter_name="Single Cell Filter",
            description=f"Single cell confidence score >= {self.min_confidence}"
        )
        result.log_result(input_result.count)
        return result

class TestKeywordSearchFilter:
    def __init__(self, conn, search_term):
        self.conn = conn
        self.search_term = search_term
    
    def apply(self, input_result):
        if input_result.data.empty or not self.search_term:
            return input_result
        
        search_mask = pd.Series([False] * len(input_result.data), index=input_result.data.index)
        search_columns = ['study_title', 'summary', 'gse_title']
        
        for col in search_columns:
            if col in input_result.data.columns:
                search_mask |= input_result.data[col].str.contains(
                    self.search_term, case=False, na=False, regex=False
                )
        
        filtered_df = input_result.data[search_mask].copy()
        result = FilterResult(
            data=filtered_df,
            count=len(filtered_df),
            filter_name="Keyword Search",
            description=f"Contains '{self.search_term}'"
        )
        result.log_result(input_result.count)
        return result

def test_functional_filter_chain():
    """
    Test the functional filter chain design.
    """
    print("ğŸ§ª Testing Functional Filter Chain Design")
    print("-" * 50)
    
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        # Create filter chain
        filters = [
            TestInitialDatasetFilter(conn),
            TestBasicAvailabilityFilter(conn),
            TestOrganismFilter(conn, ["human"]),
            TestSingleCellFilter(conn, min_confidence=2),
            TestKeywordSearchFilter(conn, "cancer")
        ]
        
        print("ğŸ” Applying filter chain...")
        print("=" * 40)
        
        result = None
        for filter_obj in filters:
            result = filter_obj.apply(result)
            
            # Check for logic errors
            if result.count < 0:
                print("âŒ Logic error: negative record count")
                return False
            
            # If no records remain, stop the chain early
            if result.count == 0:
                print("âš ï¸  No records remaining, stopping chain")
                break
        
        print("=" * 40)
        print(f"ğŸ¯ Final result: {result.count} records")
        
        # Display sample results
        if not result.data.empty:
            print("\nğŸ“‹ Sample results:")
            sample_size = min(3, len(result.data))
            for i, (idx, row) in enumerate(result.data.head(sample_size).iterrows()):
                print(f"  {i+1}. {row.get('sra_ID', 'N/A')} - {str(row.get('study_title', 'N/A'))[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Functional filter chain test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        conn.close()

def test_individual_filters():
    """
    Test the individual filter functions.
    """
    print("\nğŸ”¬ Testing Individual Filter Functions")
    print("-" * 50)
    
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        # Get initial data
        initial_filter = TestInitialDatasetFilter(conn)
        initial_result = initial_filter.apply()
        
        if initial_result.data.empty:
            print("âŒ No initial data available for testing")
            return False
        
        print(f"âœ… Initial data loaded: {initial_result.count} records")
        
        # Test basic availability filter
        basic_filter = TestBasicAvailabilityFilter(conn)
        basic_result = basic_filter.apply(initial_result)
        
        if basic_result.count > initial_result.count:
            print("âŒ Basic filter logic error: increased record count")
            return False
        
        print(f"âœ… Basic availability filter: {basic_result.count} records")
        
        # Test organism filter
        organism_filter = TestOrganismFilter(conn, ["human"])
        organism_result = organism_filter.apply(basic_result)
        
        if organism_result.count > basic_result.count:
            print("âŒ Organism filter logic error: increased record count")
            return False
        
        print(f"âœ… Organism filter: {organism_result.count} records")
        
        # Test keyword search filter
        keyword_filter = TestKeywordSearchFilter(conn, "cancer")
        keyword_result = keyword_filter.apply(organism_result)
        
        print(f"âœ… Keyword search filter: {keyword_result.count} records")
        
        return True
        
    except Exception as e:
        print(f"âŒ Individual filter test failed: {e}")
        return False
    finally:
        conn.close()

def test_filter_immutability():
    """
    Test the immutability of filters (each filter returns a new object).
    """
    print("\nğŸ›¡ï¸  Testing Filter Immutability")
    print("-" * 50)
    
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        # Get initial data
        initial_filter = TestInitialDatasetFilter(conn)
        result1 = initial_filter.apply()
        original_count = result1.count
        
        # Apply filter
        basic_filter = TestBasicAvailabilityFilter(conn)
        result2 = basic_filter.apply(result1)
        
        # Check if original result object was mutated
        if result1.count != original_count:
            print("âŒ Filter mutated original result object")
            return False
        
        # Check if new object was returned
        if result1 is result2:
            print("âŒ Filter returned same object instead of new one")
            return False
        
        print("âœ… Filters maintain immutability")
        print(f"   Original result: {result1.count} records (unchanged)")
        print(f"   New result: {result2.count} records")
        
        return True
        
    except Exception as e:
        print(f"âŒ Immutability test failed: {e}")
        return False
    finally:
        conn.close()

def test_error_handling():
    """
    Test error handling of filters.
    """
    print("\nğŸš¨ Testing Error Handling")
    print("-" * 50)
    
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        # Test empty data handling
        empty_result = FilterResult(
            data=pd.DataFrame(),
            count=0,
            filter_name="Empty Test",
            description="Empty input"
        )
        
        basic_filter = TestBasicAvailabilityFilter(conn)
        result = basic_filter.apply(empty_result)
        
        if not result.data.empty or result.count != 0:
            print("âŒ Empty data handling failed")
            return False
        
        print("âœ… Empty data handled correctly")
        
        # Test None input handling
        try:
            organism_filter = TestOrganismFilter(conn, None)
            result = organism_filter.apply(empty_result)
            print("âœ… None parameter handled correctly")
        except:
            print("âŒ None parameter not handled properly")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Error handling test failed: {e}")
        return False
    finally:
        conn.close()

def run_all_tests():
    """
    Run all test functions.
    """
    print("ğŸ§ª Functional Prefilter Design Test Suite")
    print("=" * 60)
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    tests = [
        ("Functional Filter Chain", test_functional_filter_chain),
        ("Individual Filters", test_individual_filters),
        ("Filter Immutability", test_filter_immutability),
        ("Error Handling", test_error_handling)
    ]
    
    passed = 0
    total = len(tests)
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*15} {test_name} {'='*15}")
        try:
            success = test_func()
            results.append((test_name, success))
            if success:
                passed += 1
                print(f"âœ… {test_name} PASSED")
            else:
                print(f"âŒ {test_name} FAILED")
        except Exception as e:
            print(f"ğŸ’¥ {test_name} CRASHED: {e}")
            results.append((test_name, False))
    
    # Print summary
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 60)
    
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nTotal: {total} | Passed: {passed} | Failed: {total-passed}")
    print(f"Success Rate: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\nğŸ‰ All tests passed! Your functional prefilter design is working correctly.")
        print("\nğŸ’¡ Key advantages of the new design:")
        print("   âœ… Each filter is independent and reusable")
        print("   âœ… Filters are composable and can be chained in any order")
        print("   âœ… Each filter returns a new object (immutable)")
        print("   âœ… Easy to test, debug, and maintain")
        print("   âœ… Follows functional programming principles")
    else:
        print(f"\nâš ï¸  {total-passed} test(s) failed. Please review the issues above.")
    
    return passed == total

if __name__ == "__main__":
    print("ğŸš€ Starting Functional Prefilter Design Tests")
    print("Please make sure your database credentials are set correctly!")
    print()
    
    success = run_all_tests()
    
    if success:
        print("\nâœ… All tests completed successfully!")
        print("Your new functional prefilter design is ready to use!")
        exit(0)
    else:
        print("\nâŒ Some tests failed. Please check the output above.")
        exit(1)